{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_mnist_log_file(path: Path):\n",
    "    lines = path.read_text().splitlines()\n",
    "    progress_lines = [l for l in lines if \"fit progress: (\" in l]\n",
    "    entries = []\n",
    "    first_round_start_line = [l for l in progress_lines if \"fit_round: strategy sampled\" in l][0]\n",
    "    first_round_start_time_secs = pd.to_datetime(\" \".join(first_round_start_line.split(\" \")[2:4])).total_seconds()\n",
    "    for l in progress_lines:\n",
    "        x = l.split(\"fit progress: \")[-1]\n",
    "        round, loss, metrics, time = eval(x)\n",
    "        entries.append(\n",
    "            {\n",
    "                \"round\": round,\n",
    "                \"loss\": loss,\n",
    "                \"metrics\": metrics,\n",
    "                \"accuracy\": metrics.get(\"accuracy\"),\n",
    "                \"time_since_start\": time,\n",
    "                \"time\": (time - first_round_start_time_secs) if len(entries) == 0 else (time - entries[-1][\"time_since_start\"])\n",
    "            }\n",
    "        )\n",
    "    times_agg_eval = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if idx + 1 == len(lines):\n",
    "            break\n",
    "        next_line = lines[idx + 1]\n",
    "        if \"fit_round received\" not in line:\n",
    "            continue\n",
    "        if \"fit progress: (\" in next_line:\n",
    "            t_start = pd.to_datetime(\" \".join(line.split(\" \")[2:4]))\n",
    "            t_end = pd.to_datetime(\" \".join(next_line.split(\" \")[2:4]))\n",
    "            times_agg_eval.append((t_end - t_start).total_seconds())\n",
    "    #\"time_agg_eval\": time_agg_eval,\n",
    "    df = pd.DataFrame.from_records(entries)\n",
    "    df[\"time_agg_eval\"] = times_agg_eval\n",
    "    new_dtypes = {\"time\": float, \"loss\": float, \"accuracy\": float,\n",
    "                  \"time_since_start\": float, \"round\": int,\n",
    "                  \"time_agg_eval\": float\n",
    "                  }\n",
    "    if not df.empty:\n",
    "        df = df.astype(new_dtypes)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_leaf_log_file(f_err: Path, f_out: Path):\n",
    "    out_lines = f_out.read_text().splitlines()\n",
    "\n",
    "    # Metrics\n",
    "    eval_entries = []\n",
    "    for idx, l in enumerate(out_lines):\n",
    "        matches = re.findall(r\"EvaluateRes([^\\)]+)\", l)\n",
    "        client_accs = []\n",
    "        client_cardinalities = []\n",
    "        client_losses = []\n",
    "        for m in matches:\n",
    "            eval_dict = eval(f\"dict{m})\")\n",
    "            client_acc = eval_dict.get(\"metrics\").get(\"accuracy\")\n",
    "            client_cardinality = eval_dict.get(\"num_examples\")\n",
    "            client_loss = eval_dict.get(\"loss\")\n",
    "            client_accs.append(client_acc)\n",
    "            client_cardinalities.append(client_cardinality)\n",
    "            client_losses.append(client_loss)\n",
    "        if len(matches) == 0:\n",
    "            continue\n",
    "        acc = np.average(client_accs, weights=client_cardinalities)\n",
    "        loss = np.average(client_losses, weights=client_cardinalities)\n",
    "        eval_entries.append({\n",
    "            \"round\": idx + 1,\n",
    "            \"accuracy\": acc,\n",
    "            \"loss\": loss\n",
    "        })\n",
    "    eval_entries = eval_entries[:-1]\n",
    "    df = pd.DataFrame.from_records(eval_entries)\n",
    "    if not df.empty:\n",
    "        df = df.astype({\"round\": int, \"accuracy\": float, \"loss\": float})\n",
    "\n",
    "    # Timing info\n",
    "    err_lines = f_err.read_text().splitlines()\n",
    "    timing_entries = []\n",
    "    t_start_training = None\n",
    "    for idx, line in enumerate(err_lines):\n",
    "        if \"fit_round: strategy sampled\" not in line:\n",
    "            continue\n",
    "        try:\n",
    "            received_line = err_lines[idx + 1]\n",
    "            eval_start_line = err_lines[idx + 2]\n",
    "            eval_end_line = err_lines[idx + 3]\n",
    "            assert \"evaluate_round received\" in eval_end_line\n",
    "            assert \"evaluate_round: strategy sampled\" in eval_start_line\n",
    "            assert \"fit_round received\" in received_line\n",
    "        except (IndexError, AssertionError) as e:\n",
    "            continue\n",
    "        t_fit_start = pd.to_datetime(\" \".join(line.split(\" \")[2:4]))\n",
    "        t_fit_end = pd.to_datetime(\" \".join(received_line.split(\" \")[2:4]))\n",
    "        t_eval_start = pd.to_datetime(\" \".join(eval_start_line.split(\" \")[2:4]))\n",
    "        t_eval_end = pd.to_datetime(\" \".join(eval_end_line.split(\" \")[2:4]))\n",
    "        if not t_start_training:\n",
    "            t_start_training = t_fit_start\n",
    "        total_time = (t_eval_end - t_fit_start).total_seconds()\n",
    "        timing_entries.append({\n",
    "            \"time\": total_time,\n",
    "            \"time_eval\": (t_eval_end - t_eval_start).total_seconds(),\n",
    "            \"time_agg_eval\": (t_eval_end - t_fit_end).total_seconds(),\n",
    "            \"time_clients_fit\": (t_fit_end - t_fit_start).total_seconds(),\n",
    "            \"time_since_start\": (t_eval_end - t_start_training).total_seconds()\n",
    "        })\n",
    "        #total_seconds\n",
    "#    assert len(timing_entries) == len(df)\n",
    "    timing_df = pd.DataFrame.from_records(timing_entries[:len(df)])\n",
    "\n",
    "    return df.join(timing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "dfs = []\n",
    "LOG_FOLDER = Path(\"/Users/andreas/workspace/thesis-code/out/flower-logs\")\n",
    "for f in LOG_FOLDER.glob(\"fedless_*.err\"):\n",
    "    if (len(f.name.split(\"_\"))) == 6:  # Local Client Log\n",
    "        _, dataset, clients_in_round, clients_total, local_epochs, seed = f.name.split(\"_\")\n",
    "        batch_size = 5\n",
    "    elif (len(f.name.split(\"_\"))) == 7:  # Local Client Log\n",
    "        _, dataset, clients_in_round, clients_total, local_epochs, batch_size, seed = f.name.split(\"_\")\n",
    "    else:\n",
    "        continue\n",
    "    seed = seed.split(\".\")[0]\n",
    "    if dataset == \"mnist\":  # All required data lies in .err file\n",
    "        logs_df = read_mnist_log_file(f)\n",
    "    elif dataset in [\"femnist\", \"shakespeare\"]:\n",
    "        logs_df = read_leaf_log_file(f_err=f, f_out=f.with_suffix(\".out\"))\n",
    "\n",
    "    if logs_df.empty:\n",
    "        continue\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [(\n",
    "            dataset,\n",
    "            clients_in_round,\n",
    "            clients_total,\n",
    "            local_epochs,\n",
    "            batch_size,\n",
    "            seed\n",
    "        )] * len(logs_df),\n",
    "        names=[\n",
    "            \"dataset\",\n",
    "            \"clients_in_round\",\n",
    "            \"clients_total\",\n",
    "            \"local_epochs\",\n",
    "            \"batch_size\",\n",
    "            \"seed\"\n",
    "        ]\n",
    "    )\n",
    "    df = pd.DataFrame(logs_df.values, index=index, columns=logs_df.columns)  # .reset_index()\n",
    "    df = df.astype(logs_df.dtypes)\n",
    "\n",
    "    integer_index_levels = [1, 2, 3]\n",
    "    for i in integer_index_levels:\n",
    "        df.index = df.index.set_levels(df.index.levels[i].astype(int), level=i)\n",
    "    dfs.append(df)\n",
    "dfs = pd.concat(dfs)\n",
    "dfs = dfs.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dfs.loc[{\"seed\": 25738}]\n",
    "#mnist_dfs = dfs.loc[(\"mnist\", \"100\", \"100\", \"10\")]\n",
    "mnist_dfs = dfs.loc[(\"mnist\", 75, 100, 5)]\n",
    "mnist_dfs[mnist_dfs[\"accuracy\"] >= 0.99].groupby(\"seed\").min(\"round\")[\"round\"].mean()\n",
    "#sns.lineplot(x=\"round\", y=\"accuracy\", data=mnist_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ = dfs.loc[(\"mnist\", slice(75, 100), 100, slice(1, 100)), :]\n",
    "(\n",
    "    df_[df_[\"accuracy\"] >= 0.99].groupby(by=[\"seed\", \"clients_in_round\", \"local_epochs\"]).min(\"round\")\n",
    "        .groupby([\"clients_in_round\", \"local_epochs\"])\n",
    "        .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "df_ = dfs.loc[(\"mnist\", slice(75, 100), 100, slice(1, 100)), :]\n",
    "df_ = df_[df_[\"accuracy\"] >= 0.99].groupby(level=[1, 2, 3, 4]).min(\"round\")\n",
    "df_ = df_.groupby(level=[0, 2]).mean()\n",
    "sns.barplot(y=\"round\", x=\"local_epochs\", data=df_.reset_index(), ax=ax1)  # hue=\"local_epochs\",\n",
    "\n",
    "#df_ = dfs.loc[(\"mnist\", 100, 100, slice(1, 100)), :]\n",
    "#df_ = df_[df_[\"accuracy\"] >= 0.98].groupby(level=[1, 2, 3, 4]).min(\"round\")\n",
    "#df_ = df_.groupby(level=[0, 2]).mean()\n",
    "sns.barplot(y=\"time_since_start\", x=\"local_epochs\", data=df_.reset_index(), ax=ax2)  # hue=\"local_epochs\",\n",
    "fig.set_label(f\"Test123\")\n",
    "fig.savefig(\"/Users/andreas/Desktop/comp.pdf\")\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "df_ = dfs.loc[(\"mnist\", 75, 100, slice(1, 100)), :]\n",
    "df_ = df_[df_[\"round\"] > 1]\n",
    "#sns.barplot(y=\"time\", x=\"local_epochs\", data=df_.reset_index())  #  hue=\"local_epochs\"\n",
    "sns.lineplot(y=\"time\", x=\"round\", data=df_.reset_index(), hue=\"local_epochs\", ax=axarr[0])\n",
    "sns.boxplot(y=\"time\", x=\"local_epochs\", data=df_.reset_index(), ax=axarr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ = dfs.loc[(\"femnist\", 75, 100, slice(1, 100)), :]\n",
    "df_ = df_[df_[\"round\"] > 1]\n",
    "df_[\"time_wo_agg_eval\"] = df_[\"time\"] - df_[\"time_agg_eval\"]\n",
    "df_[[\"time_wo_agg_eval\", \"time_agg_eval\"]].mean(level=[3]).plot.bar(stacked=True)\n",
    "df_.mean(level=[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "femnist_dfs = dfs.loc[(\"femnist\", 100, 100, slice(1, 100)), :]\n",
    "femnist_dfs[femnist_dfs[\"accuracy\"] >= 0.8].groupby(\"seed\").min(\"round\")[\"round\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ = dfs.loc[(\"femnist\", 100, 100, slice(1, 100)), :]\n",
    "df_ = df_[df_[\"accuracy\"] >= 0.80].groupby(level=[1, 2, 3, 4]).min(\"round\")\n",
    "df_ = df_.groupby(level=[0, 2]).mean()\n",
    "#sns.barplot(y=\"round\", x=\"local_epochs\", data=df_.reset_index()) # hue=\"local_epochs\",\n",
    "df_ = dfs.loc[(\"femnist\", 100, 100, slice(1, 100)), :]\n",
    "sns.lineplot(y=\"accuracy\", x=\"round\", data=df_.reset_index(), hue=\"local_epochs\")  # hue=\"local_epochs\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_ = dfs.loc[(\"shakespeare\", slice(1, 100), slice(1, 100), slice(1, 100)), :]\n",
    "df_ = df_[df_[\"round\"] > 1]\n",
    "df_.groupby(\"seed\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = dfs.loc[(\"shakespeare\", slice(1, 100), slice(1, 100), slice(1, 100)), :]\n",
    "sns.lineplot(y=\"accuracy\", x=\"round\", data=df_.reset_index(), hue=\"batch_size\")  # hue=\"local_epochs\",\n",
    "#sns.lineplot(y=\"time_since_start\", x=\"round\", data=df_.reset_index(), hue=\"batch_size\")  # hue=\"local_epochs\",\n",
    "#sns.lineplot(y=\"time\", x=\"round\", data=df_.reset_index(), hue=\"local_epochs\")  # hue=\"local_epochs\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}